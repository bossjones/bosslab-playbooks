# TODO: Deploy zsh pod so we can debug whenever we need to
# SOURCE: https://github.com/nicolaka/netshoot/blob/master/Dockerfile
apiVersion: apps/v1beta2 # for versions before 1.9.0 use apps/v1beta2
kind: Deployment
metadata:
  namespace: kube-system
  name: k8s-zsh-debugger-calico-deploy
  labels:
    app: k8s-zsh-debugger-calico
spec:
  selector:
    matchLabels:
      app: k8s-zsh-debugger
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app: k8s-zsh-debugger
    spec:
      serviceAccount: cni-plugin
      serviceAccountName: cni-plugin
      hostNetwork: true
      containers:
      - image: bossjones/k8s-zsh-debugger
        name: k8s-zsh-debugger
        command: ["ping","localhost"]
        volumeMounts:
        - mountPath: /calico-secrets
          name: etcd-certs
        - mountPath: /var/run/calico/bird.ctl
          name: bird-ctl
        env:
        - name: ETCD_ENDPOINTS
          value: "https://localhost:12378"
        - name: ETCD_CA_CERT_FILE
          valueFrom:
            configMapKeyRef:
              key: etcd_ca
              name: calico-config
        - name: ETCD_KEY_FILE
          valueFrom:
            configMapKeyRef:
              key: etcd_key
              name: calico-config
        - name: ETCD_CERT_FILE
          valueFrom:
            configMapKeyRef:
              key: etcd_cert
              name: calico-config
      volumes:
        - name: etcd-certs
          secret:
           defaultMode: 420
           secretName: calico-etcd-secrets
        - name: bird-ctl
          hostPath:
            path: /var/run/calico/bird.ctl
      nodeSelector:
        node-role.kubernetes.io/master: ""


---

# This manifest creates a Deployment of Typha to back the above service.

apiVersion: apps/v1beta1
kind: Deployment
metadata:
  name: k8s-zsh-debugger-calico
  namespace: {{ boss__calico__namespace_name }}
  labels:
    k8s-app: k8s-zsh-debugger-calico
spec:
  # Number of Typha replicas.  To enable Typha, set this to a non-zero value *and* set the
  # typha_service_name variable in the calico-config ConfigMap above.
  #
  # We recommend using Typha if you have more than 50 nodes.  Above 100 nodes it is essential
  # (when using the Kubernetes datastore).  Use one replica for every 100-200 nodes.  In
  # production, we recommend running at least 3 replicas to reduce the impact of rolling upgrade.
  replicas: {{ boss__calico__debugger_deployment_spec_replicas }}
  revisionHistoryLimit: 2
  selector:
   matchLabels:
    k8s-app: k8s-zsh-debugger-calico
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        k8s-app: k8s-zsh-debugger-calico
{% if boss__calico__typha_deployment_annotations is defined %}
      annotations:
{{ boss__calico__typha_deployment_annotations | indent( width=8, indentfirst=True,blank=True) }}
{% endif %}
    spec:
      nodeSelector:
        beta.kubernetes.io/os: linux
      hostNetwork: true
      tolerations:
        # Mark the pod as a critical add-on for rescheduling.
        - key: CriticalAddonsOnly
          operator: Exists
      serviceAccountName: calico-node
      containers:
      - image: bossjones/k8s-zsh-debugger:latest
        name: k8s-zsh-debugger-calico
        command:
        - "ping"
        - "localhost"
        nodeSelector:
          node-role.kubernetes.io/master: ""
      volumeMounts:
        - mountPath: /host/opt/cni/bin
          name: cni-bin-dir
        - mountPath: /host/etc/cni/net.d
          name: cni-net-dir
        - mountPath: /var/run/calico
          name: var-run-calico
      volumes:
        # Used by calico/node.
        - name: lib-modules
          hostPath:
            path: /lib/modules
        - name: var-run-calico
          hostPath:
            path: /var/run/calico
        - name: var-lib-calico
          hostPath:
            path: /var/lib/calico
        - name: xtables-lock
          hostPath:
            path: /run/xtables.lock
            type: FileOrCreate
        # Used to install CNI.
        - name: cni-bin-dir
          hostPath:
            path: /opt/cni/bin
        - name: cni-net-dir
          hostPath:
            path: /etc/cni/net.d

      # volumeMounts:
      #     - mountPath: /lib/modules
      #       name: lib-modules
      #       readOnly: true
      #     - mountPath: /run/xtables.lock
      #       name: xtables-lock
      #       readOnly: false
      #     - mountPath: /var/run/calico
      #       name: var-run-calico
      #       readOnly: false
      #     - mountPath: /var/lib/calico
      #       name: var-lib-calico
      #       readOnly: false
      # # This container installs the Calico CNI binaries
      # and CNI network config file on each node.
